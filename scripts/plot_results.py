#!/usr/bin/env python3
import csv
import glob
import os
import matplotlib.pyplot as plt
import numpy as np
from collections import defaultdict

# è¨­å®šåœ–è¡¨é¢¨æ ¼
plt.style.use('ggplot') 
RESULTS_DIR = "results"

def load_data():
    """è®€å–æ‰€æœ‰ CSV æª”æ¡ˆä¸¦è§£ææ•¸æ“š"""
    data = []
    files = glob.glob(os.path.join(RESULTS_DIR, "*.csv"))
    if not files:
        print(f"Error: No CSV files found in {RESULTS_DIR}/")
        return []

    print(f"Loading {len(files)} CSV files...")
    
    for filename in files:
        with open(filename, newline='') as f:
            reader = csv.DictReader(f)
            for row in reader:
                try:
                    # è™•ç†æ¬„ä½åç¨±å¯èƒ½å‰å¾Œæœ‰ç©ºç™½çš„å•é¡Œ
                    row = {k.strip(): v.strip() for k, v in row.items()}
                    
                    data.append({
                        'impl': row['impl'],
                        'P': int(row['P']),
                        'C': int(row['C']),
                        'threads': int(row['P']) + int(row['C']), # ç¸½åŸ·è¡Œç·’æ•¸
                        'payload_us': int(row['payload_us']),
                        'throughput': float(row['throughput']),
                        # å°‡ ns è½‰ç‚º usï¼Œæ–¹ä¾¿é–±è®€
                        'avg_lat': float(row['avg_lat']) / 1000.0,
                        'p50': float(row['p50']) / 1000.0,
                        'p99': float(row['p99']) / 1000.0,
                        'p999': float(row['p999']) / 1000.0,
                        'max_lat': float(row['max_lat']) / 1000.0
                    })
                except KeyError as e:
                    # å…¼å®¹èˆŠç‰ˆ CSV æˆ–ç•¥ééŒ¯èª¤è¡Œ
                    continue
                except ValueError as e:
                    continue
    return data

def detect_scalability_payload(data):
    """
    è‡ªå‹•åµæ¸¬å“ªä¸€å€‹ payload æ˜¯ç”¨ä¾†åš Scalability æ¸¬è©¦çš„ã€‚
    é‚è¼¯ï¼šæ‰¾å‡ºæ“æœ‰ã€Œæœ€å¤šä¸åŒåŸ·è¡Œç·’æ•¸é‡çµ„åˆã€çš„ payloadã€‚
    """
    payload_thread_counts = defaultdict(set)
    
    for d in data:
        payload_thread_counts[d['payload_us']].add(d['threads'])
        
    # æ‰¾å‡º set å¤§å°æœ€å¤§çš„é‚£å€‹ payload
    best_payload = None
    max_variations = -1
    
    for p, threads_set in payload_thread_counts.items():
        if len(threads_set) > max_variations:
            max_variations = len(threads_set)
            best_payload = p
        elif len(threads_set) == max_variations:
            # å¦‚æœæ•¸é‡ä¸€æ¨£ï¼Œå„ªå…ˆé¸ payload è¼ƒå°çš„ (é€šå¸¸è² è¼‰ä½æ›´èƒ½æ¸¬å‡º Queue æœ¬èº«ç“¶é ¸)
            if best_payload is None or p < best_payload:
                best_payload = p
                
    if best_payload is not None:
        print(f"ğŸ” Auto-detected Scalability Payload: {best_payload} Î¼s (Tested with {max_variations} different thread counts)")
    return best_payload

def get_max_threads_for_payload(data, target_payload):
    """æ‰¾å‡ºæŒ‡å®š payload ä¸‹ï¼Œæœ€å¤§çš„åŸ·è¡Œç·’æ•¸é‡ (ç”¨æ–¼ç¹ªè£½ Breakdown åœ–)"""
    subset = [d for d in data if d['payload_us'] == target_payload]
    if not subset:
        return 0
    return max(d['threads'] for d in subset)

def plot_scalability(data, target_payload):
    """åœ–è¡¨ 1: åŸ·è¡Œç·’æ•¸ vs ååé‡ (Scalability)"""
    subset = [d for d in data if d['payload_us'] == target_payload]
    
    if not subset:
        print(f"âš  No data found for payload={target_payload}us")
        return

    impls = set(d['impl'] for d in subset)
    
    plt.figure(figsize=(10, 6))
    
    markers = {'hp': 'o', 'ebr': 's', 'mutex': 'x', 'none': '^'}
    linestyles = {'hp': '-', 'ebr': '-', 'mutex': '--', 'none': ':'}

    for impl in sorted(impls):
        rows = sorted([d for d in subset if d['impl'] == impl], key=lambda x: x['threads'])
        # ä½¿ç”¨ç¸½åŸ·è¡Œç·’æ•¸ (P+C) ä½œç‚º X è»¸
        x = [r['threads'] for r in rows] 
        y = [r['throughput'] / 1_000_000 for r in rows] # M ops/sec
        
        plt.plot(x, y, label=impl, marker=markers.get(impl, 'o'), 
                 linestyle=linestyles.get(impl, '-'), linewidth=2)

    plt.title(f"Throughput Scalability (Payload={target_payload}Î¼s)")
    plt.xlabel("Total Threads (Producers + Consumers)")
    plt.ylabel("Throughput (Million ops/sec)")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.savefig(f"{RESULTS_DIR}/plot_throughput.png")
    print(f"âœ“ Saved {RESULTS_DIR}/plot_throughput.png")
    plt.close()

def plot_tail_latency(data, target_payload):
    """åœ–è¡¨ 2: åŸ·è¡Œç·’æ•¸ vs P99.9 Latency (Log Scale)"""
    subset = [d for d in data if d['payload_us'] == target_payload]
    if not subset: return

    impls = set(d['impl'] for d in subset)
    
    plt.figure(figsize=(10, 6))
    
    markers = {'hp': 'o', 'ebr': 's', 'mutex': 'x', 'none': '^'}
    
    for impl in sorted(impls):
        rows = sorted([d for d in subset if d['impl'] == impl], key=lambda x: x['threads'])
        x = [r['threads'] for r in rows]
        y = [r['p999'] for r in rows] # å·²ç¶“æ˜¯ us
        
        plt.plot(x, y, label=impl, marker=markers.get(impl, 'o'), linewidth=2)

    plt.title(f"Tail Latency P99.9 (Payload={target_payload}Î¼s)")
    plt.xlabel("Total Threads (Producers + Consumers)")
    plt.ylabel("Latency (Î¼s) - Log Scale")
    plt.yscale('log')
    plt.legend()
    plt.grid(True, which="both", ls="-", alpha=0.5)
    plt.tight_layout()
    plt.savefig(f"{RESULTS_DIR}/plot_latency_p999.png")
    print(f"âœ“ Saved {RESULTS_DIR}/plot_latency_p999.png")
    plt.close()

def plot_latency_breakdown(data, target_payload):
    """åœ–è¡¨ 3: é«˜è² è¼‰ä¸‹çš„å»¶é²åˆ†ä½ˆå°æ¯” (P50, P99, P99.9)"""
    # è‡ªå‹•æ‰¾å‡ºè©² Payload ä¸‹æ¸¬è©¦éçš„æœ€å¤§åŸ·è¡Œç·’æ•¸
    max_threads = get_max_threads_for_payload(data, target_payload)
    if max_threads == 0: return

    # 1. åˆæ­¥éæ¿¾
    raw_subset = [d for d in data if d['threads'] == max_threads and d['payload_us'] == target_payload]
    
    if not raw_subset: return

    # 2. å»é™¤é‡è¤‡ (Deduplication)
    # å¦‚æœå¤šå€‹ CSV åŒ…å«ç›¸åŒçš„ impl/threads/payload çµ„åˆï¼Œæˆ‘å€‘ç”¨å­—å…¸ä¾†åªä¿ç•™ä¸€ç­†
    unique_data = {}
    for d in raw_subset:
        unique_data[d['impl']] = d
    
    # è½‰å› list ä¸¦ä¾ç…§ impl åç¨±æ’åº
    subset = sorted(unique_data.values(), key=lambda x: x['impl'])
    
    # 3. æº–å‚™ç¹ªåœ–æ•¸æ“š
    impls = [d['impl'] for d in subset]
    p50s = [d['p50'] for d in subset]
    p99s = [d['p99'] for d in subset]
    p999s = [d['p999'] for d in subset]
    
    x = np.arange(len(impls))
    width = 0.25

    plt.figure(figsize=(10, 6))
    
    # ä½¿ç”¨ç¨å¾®é€æ˜çš„é¡è‰²è®“é‡ç–Šéƒ¨åˆ†ä¸é‚£éº¼åˆºçœ¼ï¼Œé€™è£¡åˆ†é–‹ç•«æ¢å½¢åœ–
    plt.bar(x - width, p50s, width, label='P50 (Median)', alpha=0.9)
    plt.bar(x, p99s, width, label='P99', alpha=0.9)
    plt.bar(x + width, p999s, width, label='P99.9', alpha=0.9)
    
    plt.xlabel('Implementation')
    plt.ylabel('Latency (Î¼s) - Log Scale')
    plt.title(f'Latency Distribution\n(Threads={max_threads}, Payload={target_payload}Î¼s)')
    plt.xticks(x, impls) # è¨­å®š X è»¸æ¨™ç±¤
    plt.legend()
    plt.yscale('log')    # Log Scale
    plt.grid(True, axis='y', which='both', alpha=0.3)
    
    output_path = f"{RESULTS_DIR}/plot_latency_breakdown.png"
    plt.tight_layout()
    plt.savefig(output_path)
    print(f"âœ“ Saved {output_path}")
    plt.close()

def main():
    data = load_data()
    if not data: return
    
    # è‡ªå‹•åµæ¸¬ payload
    target_payload = detect_scalability_payload(data)
    
    if target_payload is None:
        print("âŒ Could not detect a valid payload for plotting.")
        return

    plot_scalability(data, target_payload)
    plot_tail_latency(data, target_payload)
    plot_latency_breakdown(data, target_payload)

if __name__ == "__main__":
    main()