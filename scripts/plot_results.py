#!/usr/bin/env python3
"""
Performance Visualization Script for Lock-Free Queue Benchmark.

This script processes CSV results generated by `bench_queue` and generates
a comprehensive set of charts to analyze Throughput, Latency, Memory Usage,
and other key metrics across different configurations.

Usage:
    python3 plot_results.py

Prerequisites:
    - python3
    - matplotlib
    - numpy
"""

import csv
import glob
import os
import matplotlib.pyplot as plt
import numpy as np
from collections import defaultdict

# Set chart style
plt.style.use('ggplot') 
RESULTS_DIR = "results"

# ==========================================
# 1. Configuration & Constants
# ==========================================

# Color mapping for different queue implementations
COLOR_MAP_IMPL = {
    # Full Names from C++ Output
    'HazardPointer': ('lightcoral', 'firebrick'),
    'EBR':           ('lightskyblue', 'navy'),
    'MutexQueue':    ('silver', 'dimgray'),
    'NoReclamation': ('lightgreen', 'darkgreen'),
    
    # Short Names (Fallback)
    'hp':            ('lightcoral', 'firebrick'),
    'ebr':           ('lightskyblue', 'navy'),
    'mutex':         ('silver', 'dimgray'),
    'none':          ('lightgreen', 'darkgreen')
}

# Color mapping for different optimization modes (Spot Check)
COLOR_MAP_MODE = {
    'NoPool / NoBO':   '#E24A33', # Red
    'Pool / NoBO':     '#348ABD', # Blue
    'NoPool / Backoff':'#FBC15E', # Yellow
    'Pool / Backoff':  '#8EBA42'  # Green
}

def get_mode_name(is_pool, is_backoff):
    """Generates a human-readable mode name based on configuration flags."""
    pool_str = "Pool" if is_pool else "NoPool"
    bo_str = "Backoff" if is_backoff else "NoBO"
    return f"{pool_str} / {bo_str}"

def load_data():
    """
    Parses all CSV files in the RESULTS_DIR and aggregates them.
    Returns a list of dictionaries containing median values for each configuration.
    """
    if not os.path.exists(RESULTS_DIR):
        print(f"Error: Directory '{RESULTS_DIR}' not found.")
        return []

    files = glob.glob(os.path.join(RESULTS_DIR, "*.csv"))
    if not files:
        print(f"Error: No CSV files found in {RESULTS_DIR}/")
        return []

    print(f"Loading {len(files)} CSV files...")
    raw_groups = defaultdict(list)
    
    for filename in files:
        fname = os.path.basename(filename)
        # Determine configuration from filename
        is_pool = "pool" in fname and "nopool" not in fname
        is_backoff = "backoff" in fname and "nobackoff" not in fname
        
        with open(filename, newline='') as f:
            reader = csv.DictReader(f)
            for row in reader:
                try:
                    impl = row['impl'].strip()
                    p_val = int(row['P'])
                    c_val = int(row['C'])
                    payload = int(row['payload_us'])
                    
                    # Group key for aggregation
                    key = (impl, is_pool, is_backoff, p_val, c_val, payload)
                    
                    entry = {
                        'throughput_prod': float(row['throughput_prod']),
                        'throughput_cons': float(row['throughput_cons']),
                        'avg_lat': float(row['avg_lat']) / 1000.0,       # Convert ns to us
                        'p50': float(row['p50']) / 1000.0,
                        'p99': float(row['p99']) / 1000.0,
                        'p999': float(row['p999']) / 1000.0,
                        'max_lat': float(row['max_lat']) / 1000.0,
                        'peak_mem_mb': float(row['peak_mem_kb']) / 1024.0, # Convert KB to MB
                        'max_depth': int(row['max_depth'])
                    }
                    raw_groups[key].append(entry)
                except (KeyError, ValueError) as e:
                    # Backward compatibility for older CSV formats
                    if 'p999' not in entry and 'max_lat' in entry:
                         entry['p999'] = entry['max_lat']
                    continue

    aggregated_data = []
    print(f"Aggregating data from {len(raw_groups)} configurations (Median of runs)...")
    
    # Calculate median for each metric to exclude outliers
    for key, entries in raw_groups.items():
        impl, is_pool, is_backoff, p_val, c_val, payload = key
        
        final_entry = {
            'raw_impl': impl,
            'is_pool': is_pool,
            'is_backoff': is_backoff,
            'mode_name': get_mode_name(is_pool, is_backoff),
            'display_impl': impl, 
            'P': p_val,
            'C': c_val,
            'payload_us': payload,
            'runs_count': len(entries)
        }
        
        metrics = ['throughput_prod', 'throughput_cons', 
                   'avg_lat', 'p50', 'p99', 'p999', 'max_lat', 
                   'peak_mem_mb', 'max_depth']
        for metric in metrics:
            vals = [e[metric] for e in entries]
            final_entry[metric] = np.median(vals)
            
        aggregated_data.append(final_entry)
        
    return aggregated_data

# ==========================================
# Helper: Generic Line Plotter
# ==========================================
def plot_simple_line(data, x_key, y_key, title_main, y_label, filename, log_scale=False, y_limit=None):
    """Generates a line chart for a specific metric across implementations."""
    target_mode = "Pool / Backoff"
    
    # Filter for the optimized configuration first
    subset = [d for d in data if d['mode_name'] == target_mode]
    
    # Fallback if specific mode data is missing
    if not subset:
        subset = data
        title_suffix = " (All Modes)"
    else:
        title_suffix = f" ({target_mode})"

    raw_impls = sorted(list(set(d['raw_impl'] for d in subset)))
    
    plt.figure(figsize=(10, 6))
    
    for impl in raw_impls:
        rows = sorted([d for d in subset if d['raw_impl'] == impl], key=lambda r: r[x_key])
        if not rows: continue
        
        color = COLOR_MAP_IMPL.get(impl, ('gray', 'black'))[1]
        
        x = [r[x_key] for r in rows]
        y = [r[y_key] for r in rows]
        
        plt.plot(x, y, label=impl, color=color, marker='o', linewidth=2.5, alpha=0.9)
        
    plt.title(title_main + title_suffix)
    plt.xlabel("Threads (P=C)" if x_key == 'P' else "Payload Size (μs)")
    plt.ylabel(y_label)
    if log_scale: plt.yscale('log')
    if y_limit: plt.ylim(y_limit)
    plt.legend()
    plt.grid(True, which="both", ls="-", alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(f"{RESULTS_DIR}/{filename}")
    print(f"✓ Saved {RESULTS_DIR}/{filename}")
    plt.close()

# ==========================================
# Chart Logic Wrappers
# ==========================================

# 1a. Consumer Throughput Scalability
def plot_throughput_scalability(data, target_payload):
    subset = [d for d in data if d['payload_us'] == target_payload]
    for d in subset: d['_tp_million'] = d['throughput_cons'] / 1_000_000
    plot_simple_line(subset, 'P', '_tp_million', f"Consumer Throughput (Payload={target_payload}μs)", 
                     "Throughput (M ops/sec)", "1_throughput_scalability.png")

# 1b. Producer Throughput Scalability
def plot_producer_throughput_scalability(data, target_payload):
    subset = [d for d in data if d['payload_us'] == target_payload]
    for d in subset: d['_tp_million'] = d['throughput_prod'] / 1_000_000
    plot_simple_line(subset, 'P', '_tp_million', f"Producer Throughput (Payload={target_payload}μs)", 
                     "Throughput (M ops/sec)", "1b_producer_throughput_scalability.png")

# 2. Tail Latency Scalability (P99.9)
def plot_latency_scalability(data, target_payload):
    subset = [d for d in data if d['payload_us'] == target_payload]
    plot_simple_line(subset, 'P', 'p999', f"P99.9 Latency (Payload={target_payload}μs)", 
                     "Latency (μs)", "2_latency_scalability_p999.png", log_scale=True)

# 3. Latency Distribution (Bar Chart: P50, P99, P99.9, Max)
def plot_latency_distribution(data, target_payload):
    target_mode = "Pool / Backoff"
    target_p = 8 # Fixed thread count for detailed breakdown
    
    subset = [d for d in data if d['payload_us'] == target_payload and d['P'] == target_p and d['mode_name'] == target_mode]
    if not subset:
        subset = [d for d in data if d['payload_us'] == target_payload and d['P'] == target_p]
        if not subset: return

    subset.sort(key=lambda x: x['raw_impl'])
    
    labels = [d['raw_impl'] for d in subset]
    metrics = ['p50', 'p99', 'p999', 'max_lat']
    metric_labels = ['P50', 'P99', 'P99.9', 'Max']
    colors = ['skyblue', 'orange', 'firebrick', 'purple']
    
    x = np.arange(len(labels))
    width = 0.2

    plt.figure(figsize=(12, 6))
    
    for i, (metric, color, label) in enumerate(zip(metrics, colors, metric_labels)):
        values = [d[metric] for d in subset]
        offset = (i - 1.5) * width
        plt.bar(x + offset, values, width, label=label, color=color, edgecolor='black')
    
    plt.xlabel('Implementation')
    plt.ylabel('Latency (μs) - Log Scale')
    plt.title(f'Latency Distribution (Threads={target_p} (P=C={target_p}), Payload={target_payload}μs)\n({target_mode})')
    plt.xticks(x, labels, rotation=0)
    plt.yscale('log')
    plt.legend()
    plt.grid(True, axis='y', which='both', alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(f"{RESULTS_DIR}/3_latency_distribution.png")
    print(f"✓ Saved {RESULTS_DIR}/3_latency_distribution.png")
    plt.close()

# 4. Memory Usage Scalability
def plot_memory_scalability(data, target_payload):
    subset = [d for d in data if d['payload_us'] == target_payload]
    plot_simple_line(subset, 'P', 'peak_mem_mb', f"Peak Memory (Payload={target_payload}μs)", 
                     "Memory (MB)", "4_memory_scalability.png")

# 5. Queue Depth Scalability
def plot_max_depth_scalability(data, target_payload):
    subset = [d for d in data if d['payload_us'] == target_payload]
    plot_simple_line(subset, 'P', 'max_depth', f"Max Depth (Payload={target_payload}μs)", 
                     "Depth", "5_max_depth_scalability.png")

# 6. Payload Sensitivity Analysis
def plot_payload_sensitivity(data, target_p):
    subset = [d for d in data if d['P'] == target_p]
    for d in subset: d['_tp_million'] = d['throughput_cons'] / 1_000_000
    plot_simple_line(subset, 'payload_us', '_tp_million', f"Payload Sensitivity (P=C={target_p})", 
                     "Throughput (M ops/sec)", "6_payload_sensitivity.png")

# 7. Efficiency Analysis
def plot_efficiency_sensitivity(data, target_p):
    subset = [d for d in data if d['P'] == target_p and d['payload_us'] > 0]
    for d in subset:
        # Calculate theoretical maximum throughput (Ideal = Threads / TaskTime)
        ideal = d['C'] * (1_000_000.0 / d['payload_us'])
        d['_eff'] = (d['throughput_cons'] / ideal) * 100.0
    plot_simple_line(subset, 'payload_us', '_eff', f"Efficiency (P=C={target_p})", 
                     "Efficiency (%)", "7_efficiency_sensitivity.png", y_limit=(0, 110))

# ==========================================
# 8. Spot Check (Optimization Impact)
# ==========================================
def plot_spot_check_4_modes(data, target_p, target_payload):
    """
    Generates a 3x2 grid comparison of different optimization modes:
    - NoPool / NoBO
    - Pool / NoBO
    - NoPool / Backoff
    - Pool / Backoff
    """
    subset = [d for d in data if d['P'] == target_p and d['payload_us'] == target_payload]
    if not subset: 
        print(f"Warning: No data found for P={target_p}, Payload={target_payload}")
        return

    modes_order = ['NoPool / NoBO', 'Pool / NoBO', 'NoPool / Backoff', 'Pool / Backoff']
    impls = sorted(list(set(d['raw_impl'] for d in subset)))
    
    fig, axes = plt.subplots(3, 2, figsize=(16, 19))
    fig.suptitle(f"Spot Check Comparison (P=C={target_p}, Payload={target_payload}μs)\n(Median of 5 runs)", fontsize=16)
    
    charts_config = [
        (axes[0, 0], 'throughput_prod', 'Producer Throughput', 'M Ops/Sec', 'linear'),
        (axes[0, 1], 'throughput_cons', 'Consumer Throughput', 'M Ops/Sec', 'linear'),
        (axes[1, 0], 'peak_mem_mb', 'Peak Memory', 'MB', 'linear'),
        (axes[1, 1], 'max_depth', 'Max Queue Depth', 'Count', 'linear'),
        (axes[2, 0], 'p99', 'P99 Latency', 'μs', 'log'),
        (axes[2, 1], 'p999', 'P99.9 Latency', 'μs', 'log')
    ]

    x = np.arange(len(impls))
    bar_width = 0.2
    legend_handles = []
    legend_labels = []

    for ax, metric, title, ylabel, scale in charts_config:
        for i, mode in enumerate(modes_order):
            values = []
            for impl in impls:
                found = next((d for d in subset if d['raw_impl'] == impl and d['mode_name'] == mode), None)
                val = found[metric] if found else 0
                if 'throughput' in metric: val /= 1_000_000
                values.append(val)
            
            offset = (i - 1.5) * bar_width
            bars = ax.bar(x + offset, values, bar_width, label=mode, 
                          color=COLOR_MAP_MODE.get(mode, 'gray'), edgecolor='black')
            
            # Collect handles for the unified legend
            if ax == axes[0, 0] and i < len(modes_order):
                legend_handles.append(bars)
                legend_labels.append(mode)

        ax.set_title(title)
        ax.set_ylabel(ylabel)
        ax.set_xticks(x)
        ax.set_xticklabels(impls)
        if scale == 'log': ax.set_yscale('log')
        ax.grid(True, axis='y', alpha=0.3)

    plt.subplots_adjust(bottom=0.10, hspace=0.3, top=0.93)
    
    fig.legend(legend_handles, legend_labels, 
               loc='lower center',            
               bbox_to_anchor=(0.5, 0.02),    
               ncol=2,                        
               fontsize='large', 
               title="Configuration", title_fontsize='large',
               frameon=True, fancybox=True, shadow=True)

    output_file = f"8_spot_check_P{target_p}_Payload{target_payload}.png"
    plt.savefig(os.path.join(RESULTS_DIR, output_file))
    print(f"✓ Saved {os.path.join(RESULTS_DIR, output_file)}")
    plt.close()

# ==========================================
# Main Execution
# ==========================================
def detect_base_params(data):
    """Auto-detects the most common parameter set in the result data."""
    main_data = [d for d in data if d['is_pool'] and d['is_backoff']]
    if not main_data: main_data = data
    
    counts = defaultdict(set)
    for d in main_data: counts[d['payload_us']].add(d['P'])
    p_load = max(counts.items(), key=lambda x: len(x[1]))[0] if counts else None

    counts = defaultdict(set)
    for d in main_data: counts[d['P']].add(d['payload_us'])
    p_threads = max(counts.items(), key=lambda x: len(x[1]))[0] if counts else None
    
    return p_load, p_threads

def main():
    data = load_data()
    if not data: return
    
    p_load, p_threads = detect_base_params(data)
    print(f"\nDetected Base Parameters:\n  - Payload: {p_load} us\n  - Threads: {p_threads}")
    
    # Generate charts
    if p_load is not None:
        plot_throughput_scalability(data, p_load)
        plot_producer_throughput_scalability(data, p_load)
        plot_latency_scalability(data, p_load)
        plot_latency_distribution(data, p_load)
        plot_memory_scalability(data, p_load)
        plot_max_depth_scalability(data, p_load)
    
    if p_threads is not None:
        plot_payload_sensitivity(data, p_threads)
        plot_efficiency_sensitivity(data, p_threads)
        
    # Generate Spot Check for specific scenario (P=8, Payload=3)
    spot_check_p = 8
    spot_check_payload = 3
    print(f"\nGenerating Spot Check for P={spot_check_p}, Payload={spot_check_payload}...")
    plot_spot_check_4_modes(data, spot_check_p, spot_check_payload)

    print("\n✅ All plots generated successfully!")

if __name__ == "__main__":
    main()